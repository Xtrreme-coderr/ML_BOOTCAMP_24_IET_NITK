{"cells":[{"cell_type":"markdown","metadata":{"id":"wbtcrGFuEwY8"},"source":["# üßë‚Äçüè´ Task 1 Part 1: Building a Spam Classifier with Naive Bayes\n","In this exercise, you'll implement a spam classifier using the **Naive Bayes algorithm** . You'll work with email data to classify messages as spam or non-spam (ham). Follow the steps below and fill in the code where indicated.\n","\n","**Objective:** Implement all key components of an ML pipeline (except for data handling).\n","\n","**Allowed Libraries:** `pandas`, `numpy`\n","\n","**Not Allowed:** Any pre-built ML algorithms or functions like those from `sklearn`.\n","\n","Follow the instructions step-by-step and answer the questions!"]},{"cell_type":"markdown","metadata":{"id":"hIcbfFllEwZH"},"source":["## Step 1: Data Loading and Preprocessing\n","First, let's load and examine our data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VKNMYMD7EwZL"},"outputs":[],"source":["# Load the data\n","# TODO: Load the 'emails.csv' file into a DataFrame called 'emails'\n","import pandas as pd\n","emails = pd.read_csv(\"emails.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yvWzxQvEEwZQ"},"outputs":[],"source":["# Display the first few rows\n","print(emails.head())\n","\n","# HINT: Use pd.read_csv() to load the data\n","# HINT: The DataFrame should have 'text' and 'spam' columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"52DBESNHEwZS"},"outputs":[],"source":["#Analyse the data and remove or modify rows with missing or invalid values"]},{"cell_type":"markdown","metadata":{"id":"6FX55vNzEwZV"},"source":["## Step 2: Text Preprocessing\n","We need to process each email to extract unique words."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SHtEmNrUEwZX"},"outputs":[],"source":["def process_email(text):\n","    text=text.lower()\n","    words=list(map(str,text.split(\" \")))\n","    words=list(set(words))\n","    # TODO: Implement the preprocessing function\n","    # 1. Convert text to lowercase\n","    # 2. Split into words\n","    # 3. Remove duplicates\n","\n","    # Your code here\n","\n","    # HINT: Use text.lower() for lowercase conversion\n","    # HINT: Use split() to convert text to words\n","    # HINT: Use set() to remove duplicates\n","    return words"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QXAjA9hREwZa"},"outputs":[],"source":["# Apply preprocessing to all emails\n","emails[\"processed_text\"=email[\"text\"].apply(process_email)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OhxeoFiMEwZc"},"outputs":[],"source":["# Test your preprocessing by testing on the first email\n","first=emails[\"text\"].iloc[0]\n","processed=process_email(first)\n","print(first,processed,sep=\"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"7gfrMOKWEwZf"},"source":["## Step 3: Calculate Prior Probabilities\n","Let's calculate the basic probability of an email being spam."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ry85fhWIEwZh"},"outputs":[],"source":["# TODO: Calculate the following:\n","# 1. Total number of emails\n","# 2. Number of spam emails\n","# 3. Probability of spam\n","\n","num_emails = len(emails)\n","num_spam = sum(emails[\"spam\"])\n","spam_probability = num_spam/num_emails\n","\n","print(f\"Number of emails: {num_emails}\")\n","print(f\"Number of spam emails: {num_spam}\")\n","print(f\"Probability of spam: {spam_probability:.4f}\")\n","\n","# HINT: Use len(emails) for total count\n","# HINT: Use sum(emails['spam']) for spam count"]},{"cell_type":"markdown","metadata":{"id":"A3-xvh1AEwZk"},"source":["## Step 4: Training the Model\n","Now we'll build our Naive Bayes model by counting word occurrences in spam and ham emails."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OkYc1rjjEwZm"},"outputs":[],"source":["def train_naive_bayes(emails_data):\n","    model = {}\n","\n","    for index, row in emails_data.iterrows():\n","        words=process_email(row[\"text]\")\n","        for word in words:\n","            if word not in model:\n","                model[word]={\"spam\"=0, \"ham\"=0}\n","            if row[\"spam\"]==1:\n","                model[word][\"spam\"]+=1\n","            else:\n","                model[word][\"ham\"]+=1\n","            model[word][\"spam\"]+=1\n","            model[word][\"ham\"]+=1\n","    # HINT: Initialize counts with 1 (Laplace smoothing)\n","    # HINT: Structure: model[word] = {'spam': count, 'ham': count}\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p4IvERrFEwZo"},"outputs":[],"source":["model = train_naive_bayes(emails)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ofyk7tzbEwZq"},"outputs":[],"source":["# Test your model with some words\n","# Examples: 'lottery', 'sale', 'meeting'\n","\n","print(model[\"lottery\"],model[\"sale\"],model[\"meeting\"])"]},{"cell_type":"markdown","metadata":{"id":"yqObm_DkEwZs"},"source":["## Step 5: Implementing the Prediction Function\n","Finally, let's implement the function to predict whether an email is spam."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bXrKjo_uEwZu"},"outputs":[],"source":["\n","import math as m\n","def predict_naive_bayes(email_text, model, num_spam, num_ham):\n","    words=process_email(email_text)\n","    log_spam=m.log(num_spam/(num_spam+num_ham))\n","    log_ham=m.log(num_ham/(num_spam+num_ham))\n","    for word in words:\n","        spam_words=model[word][spam]\n","        spam_words=model[word][ham]\n","    log_spam+=m.log((spam_count+1)/(num_spam+len(model))\n","    log_ham+=m.log((ham_count+1)/(num_ham+len(model))\n","    probability=1/(1+m.exp(log_ham-log_spam))\n","    return probability\n","\n","    pass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"epcZ8T4fEwZw"},"outputs":[],"source":["# Test your prediction function\n","test_emails = [\n","    \"lottery winner claim prize money\",\n","    \"meeting tomorrow at 3pm\",\n","    \"buy cheap watches online\"\n","]"]},{"cell_type":"markdown","metadata":{"id":"n39HmwzJEwZx"},"source":["## Step 6: Wrap-up\n","1. How well did your model perform?\n","2. What challenges did you face while implementing it from scratch?\n","3. What improvements would you suggest for the future?"]},{"cell_type":"markdown","metadata":{"id":"FNeKnCDDEwZz"},"source":["### Notes (if any):"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python"},"colab":{"provenance":[{"file_id":"https://github.com/b-anagha/ML_BOOTCAMP_24_IET_NITK/blob/main/Session1/Tasks/Task%201%20-%20Naive_Bayes/Task-1_Part1.ipynb","timestamp":1730660725519}]}},"nbformat":4,"nbformat_minor":0}